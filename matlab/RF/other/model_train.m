% 

inputTable = scale_zscore(smart_tr5, 1);
predictorNames = {'smart_5_raw',...
    'smart_187_raw',...
    'smart_197_raw',... 
    'smart_1_normalized',... 
    'smart_4_raw',... 
    'smart_7_normalized',...  
    'smart_9_normalized',...  
    'smart_12_raw',...  
    'smart_183_raw',...  
    'smart_184_raw',...  
    'smart_189_raw',...  
    'smart_193_normalized',...  
    'smart_198_raw',...  
    'smart_199_raw',...  
    'smart_3_normalized',...  
    'smart_5_normalized',...  
    'smart_7_raw',...  
    'smart_9_raw',...  
    'smart_183_normalized',...  
    'smart_184_normalized',...  
    'smart_187_normalized',...  
    'smart_188_normalized',...  
    'smart_188_raw',...  
    'smart_189_normalized',...  
    'smart_192_raw',...  
    'smart_193_raw',...  
    'smart_194_raw',...  
    'smart_197_normalized',...  
    'smart_198_normalized'};
predictors = inputTable{:, predictorNames};
response = inputTable.class;

%% train a classification tree
% model_tree = fitctree(...
%     predictors, ...
%     response, ...
%     'SplitCriterion', 'gdi', ...
%     'MaxNumSplits', 100, ...
%     'Surrogate', 'off', ...
%     'ClassNames', [0; 1]);

%% train random forests
template = templateTree(...
    'MaxNumSplits', 50);
model_rf = fitcensemble(...
    predictors, ...
    response, ...
    'Method', 'Bag', ...
    'NumLearningCycles', 100, ...
    'Learners', template, ...
    'ClassNames', [0; 1]);

%% train a svm
gamma = 1; cost = 0.5;
svm_option = sprintf('-s 0 -t 2 -g %g -c %g', gamma, cost);
model_svm = svmtrain(...
    response, ...
    predictors, ...
    svm_option);
